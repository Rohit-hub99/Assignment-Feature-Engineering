{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Assignment Questions\n"
      ],
      "metadata": {
        "id": "9t0eKubNOsJ9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. What is a parameter?\n",
        "  - In the context of machine learning, a parameter refers to a configuration variable that is learned from the training data by the model.\n",
        "\n",
        "  -  Key Characteristics of Parameters:\n",
        "    - Learned during training.\n",
        "    - Define the model itself.\n",
        "    - Examples: weights in neural networks, coefficients in linear regression, etc.\n",
        "\n",
        "\n",
        "# 2. What is correlation?\n",
        "  - Correlation is a statistical measure that shows the strength and direction of a relationship between two variables.\n",
        "\n",
        "   - Key Points:\n",
        "     - It tells us how closely two variables move together.\n",
        "     - The value of correlation ranges between -1 and +1.\n",
        "  \n",
        "   - Correlation helps us understand which features are strongly related to the target variable or to each other.\n",
        "   - It‚Äôs useful for feature selection ‚Äî to keep the most relevant features and avoid multicollinearity.\n",
        "\n",
        "  What does negative correlation mean?\n",
        "     - A negative correlation means that as one variable increases, the other variable decreases, and vice versa.\n",
        "     - In feature engineering, if two features have a strong negative correlation, one might be used to predict the other ‚Äî or you might decide to remove one if it‚Äôs not helpful for the model.\n",
        "\n",
        "\n",
        "\n",
        "# 3. Define Machine Learning. What are the main components in Machine Learning?\n",
        "  - Machine Learning (ML) is a branch of Artificial Intelligence (AI) that enables computers to learn from data and make predictions or decisions without being explicitly programmed.\n",
        "\n",
        "  - Main Components in Machine Learning\n",
        "    - Data:\n",
        "      - The foundation of ML ‚Äî includes both features (inputs) and target (output).\n",
        "      - Example: For predicting house prices:\n",
        "        - Features: size, number of bedrooms\n",
        "        - Target: house price\n",
        "    \n",
        "    - Model\n",
        "      - An algorithm that learns patterns from the data.\n",
        "      - Examples: Linear Regression, Decision Tree, Random Forest, etc.\n",
        "   \n",
        "    - Training\n",
        "      - The process of feeding data to the model so it can learn the relationship between inputs and outputs.\n",
        "\n",
        "    - Prediction/Inference\n",
        "      - Once trained, the model can make predictions on new, unseen data.\n",
        "\n",
        "    - Evaluation\n",
        "      - Checking how well the model performs using metrics like:\n",
        "        - Accuracy, Precision, Recall (for classification)\n",
        "        - MSE, RMSE (for regression)\n",
        "\n",
        "    - Features\n",
        "      - The input variables used for training the model.\n",
        "      - Feature Engineering is a key part of this step (which you're learning now!).\n",
        "\n",
        "    - Algorithm\n",
        "      - The mathematical logic or method that the model uses to learn from data.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 4. How does loss value help in determining whether the model is good or not?\n",
        "  - The loss value tells us how far off the model‚Äôs predictions are from the actual values.\n",
        "     - Low loss = Model is predicting well (close to actual values).\n",
        "     - High loss = Model is making poor predictions (far from actual values).\n",
        "\n",
        "\n",
        "# 5. What are continuous and categorical variables?\n",
        "  - 1. Continuous Variables:\n",
        "     - These are numerical values that can take any value within a range ‚Äî including decimals.\n",
        "     - Examples:\n",
        "       - Age (22.5 years)\n",
        "       - Height (5.9 feet)\n",
        "       - Salary (‚Çπ55,000.75)\n",
        "       - Temperature (37.2¬∞C)\n",
        "     - They are measurable and can be infinite in precision.\n",
        "\n",
        "  - 2. Categorical Variables:\n",
        "     - These represent distinct groups or categories. They usually take on a limited number of values (often labels or names).\n",
        "     - Examples:\n",
        "       - Gender (Male, Female, Other)\n",
        "       - City (Mumbai, Delhi, Bangalore)\n",
        "       - Product Type (Electronics, Clothing, Groceries)\n",
        "     - They are not measured ‚Äî they are labeled or grouped.\n",
        "\n",
        "\n",
        "\n",
        "# 6. How do we handle categorical variables in Machine Learning? What are the common techniques?\n",
        "  - Machine learning algorithms cannot process strings or labels directly, so we need to encode categorical variables into numbers.\n",
        "\n",
        "  - Common Techniques to Handle Categorical Variables:\n",
        "    - 1. Label Encoding\n",
        "      - Converts categories into numeric labels (0, 1, 2, ‚Ä¶).\n",
        "      - Suitable for ordinal data (where order matters)\n",
        "    \n",
        "    - 2. One-Hot Encoding\n",
        "      - Creates a new binary column for each category.\n",
        "      - Values are 0 or 1.\n",
        "\n",
        "    - 3. Ordinal Encoding\n",
        "      - Similar to label encoding, but you define the order\n",
        "\n",
        "    - 4. Frequency Encoding\n",
        "      - Replace each category with how often it appears.\n",
        "\n",
        "    - 5. Target Encoding (Mean Encoding)\n",
        "      - Replace category with the mean of the target variable for that category\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "# 7. What do you mean by training and testing a dataset?\n",
        "  - In Machine Learning, we split the dataset into two main parts:\n",
        "\n",
        "  - 1. Training Dataset\n",
        "    - This is the part of the data used to teach the model.\n",
        "    - The model learns patterns and relationships from this data.\n",
        "    - Usually takes up 70% to 80% of the entire dataset.\n",
        "\n",
        "  - 2. Testing Dataset\n",
        "    - This part is used to evaluate how well the trained model performs on new, unseen data.\n",
        "    - It checks the generalization ability of the model.\n",
        "    - Usually takes up 20% to 30% of the dataset.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 8. What is sklearn.preprocessing?\n",
        "  - sklearn.preprocessing is a module in the Scikit-learn library that provides tools to prepare and transform data before feeding it into a machine learning model.\n",
        "\n",
        "\n",
        "\n",
        "# 9. What is a Test set?\n",
        "  - A test set is a portion of the dataset that is not used during training. Instead, it's used to evaluate the performance of a machine learning model after it has been trained.\n",
        "\n",
        "  - Purpose:\n",
        "    - To check how well the model performs on unseen data.\n",
        "    - It helps determine whether the model can generalize beyond the training data.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 10. How do we split data for model fitting (training and testing) in Python?\n",
        "  - We use the train_test_split() function from Scikit-learn to split our dataset into:\n",
        "    - Training set: used to train the model\n",
        "    - Testing set: used to evaluate the model\n",
        "\n",
        "   How do you approach a Machine Learning problem?\n",
        "\n",
        "     - Understand the Problem (Domain Knowledge)\n",
        "       - What are you trying to predict or classify?\n",
        "       - What‚Äôs the goal ‚Äî Accuracy? Revenue? Time-saving?\n",
        "       - Is it a classification, regression, or clustering task?\n",
        "    \n",
        "     - Collect & Explore the Data (EDA üîç)\n",
        "       - Load the dataset (CSV, SQL, API, etc.)\n",
        "       - Check shape, types, and summary stats\n",
        "       - Visualize key features: histograms, boxplots, scatterplots\n",
        "       - Check for missing values, outliers, duplicates\n",
        "\n",
        "\n",
        "\n",
        "# 11. Why do we have to perform EDA before fitting a model to the data?\n",
        "  - EDA (Exploratory Data Analysis) is like getting to know your data before trusting it. It helps you:\n",
        "     - Understand the structure\n",
        "     - Detect issues\n",
        "     - Discover patterns\n",
        "     - And ultimately make better decisions for model building\n",
        "\n",
        "  - Here's Why EDA Is Important:\n",
        "    - 1. Understand the Data\n",
        "       - What are the columns?\n",
        "       - What types of variables are they? (categorical, continuous)\n",
        "       - Are they relevant to the problem?\n",
        "\n",
        "    -  2. Detect Missing or Corrupt Data\n",
        "       - Many ML models can‚Äôt handle missing values.\n",
        "       - EDA helps you find and decide whether to fill, drop, or flag them.\n",
        "\n",
        "    - 3. Spot Outliers and Anomalies\n",
        "      - Outliers can distort model performance.\n",
        "      - You might want to remove or treat them.\n",
        "\n",
        "    - 4. Check Distributions\n",
        "      - Helps decide which preprocessing steps are needed:\n",
        "         - Normalization or Standardization?\n",
        "         - Log transformation?\n",
        "\n",
        "\n",
        "\n",
        "# 12. What is correlation?\n",
        "  - same as 2nd question's answer\n",
        "\n",
        "\n",
        "\n",
        "# 13. What does negative correlation mean?\n",
        "  - Negative correlation means that as one variable increases, the other decreases.\n",
        "\n",
        "  -  Example:\n",
        "    - Outdoor Temperature ‚Üë ‚Üí Sales of Winter Jackets ‚Üì\n",
        "    - Hours Spent Watching TV ‚Üë ‚Üí Grades in School ‚Üì (possibly!)\n",
        "  - These pairs have negative relationships ‚Äî as one goes up, the other tends to go down.\n",
        "\n",
        "\n",
        "\n",
        "# 14. How can you find correlation between variables in Python?\n",
        "  - steps:\n",
        "     \n",
        "     - Using pandas.corr()\n",
        "#import pandas as pd\n",
        "\n",
        "# Load your dataset\n",
        "#df = pd.read_csv('your_dataset.csv')\n",
        "\n",
        "# Correlation matrix\n",
        "#correlation_matrix = df.corr()\n",
        "\n",
        "# Print it\n",
        "#print(correlation_matrix)\n",
        "\n",
        "     - Visualize with a Heatmap (Optional but Powerful)\n",
        "\n",
        "#  import seaborn as sns\n",
        "#import matplotlib.pyplot as plt\n",
        "\n",
        "#plt.figure(figsize=(10, 8))\n",
        "#sns.heatmap(df.corr(), annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "#plt.title(\"Correlation Matrix\")\n",
        "#plt.show()\n",
        "\n",
        "\n",
        "\n",
        "# 15. What is causation? Explain difference between correlation and causation with an example.\n",
        "  - Causation means one variable directly affects or causes a change in another.\n",
        "\n",
        "  \n",
        "  - Correlation vs. Causation\n",
        "\n",
        "  - Correlation\n",
        "    - Relationship\n",
        "      Variables move together\n",
        "    - Direction\n",
        "      No specific direction\n",
        "    - Proof\n",
        "      Statistical (but not always meaningful)\n",
        "    - Example\n",
        "      Ice cream sales ‚Üë ‚Üî Drowning cases ‚Üë\n",
        "\n",
        "  - Causation\n",
        "    - Relationship\n",
        "      One variable causes the other\n",
        "    - Direction\n",
        "      Directional (A ‚Üí B)\n",
        "    - Proof\n",
        "      Requires deeper evidence or experiments\n",
        "    - Example\n",
        "      Smoking ‚Üí Lung cancer\n",
        "\n",
        "\n",
        "\n",
        "# 16. What is an Optimizer? What are different types of optimizers? Explain each with an example.\n",
        "   - An optimizer is an algorithm that adjusts the model's weights to minimize the loss function during training.\n",
        "\n",
        "  - different types of Optimizers\n",
        "    \n",
        "    - 1. Gradient Descent (GD)\\\n",
        "      - Moves in the direction of steepest descent (negative gradient)\n",
        "      - Updates weights after using entire dataset\n",
        "      - Not used much in deep learning due to slowness\n",
        "\n",
        "    - 2. Stochastic Gradient Descent (SGD)\n",
        "      - Updates weights after each training sample\n",
        "      - Faster, but has more fluctuations\n",
        "\n",
        "    - 3. Mini-batch Gradient Descent\n",
        "      - A middle ground: updates weights after small batches of data\n",
        "      - Faster & more stable than SGD\n",
        "\n",
        "    - 4. Adam (Adaptive Moment Estimation)\n",
        "      - Combines Momentum and RMSProp\n",
        "      - Very popular for deep learning tasks\n",
        "      - Adjusts learning rate for each parameter individually\n",
        "      \n",
        "    - 5. RMSProp\n",
        "      - Keeps track of past gradients and adjusts learning rate accordingly\n",
        "      - Works well for RNNs and deep networks\n",
        "    \n",
        "    - 6. Adagrad\n",
        "      - Adjusts learning rate based on frequency of parameters\n",
        "      - Works well for sparse data (like NLP or recommender systems)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 17. What is sklearn.linear_model ?\n",
        "  - sklearn.linear_model is a module in Scikit-learn that provides classes to implement linear models for:\n",
        "     - Regression\n",
        "     - Classification\n",
        "    \n",
        "  - It contains models like Linear Regression, Logistic Regression, Ridge, Lasso, etc.\n",
        "\n",
        "\n",
        "\n",
        "# 18. What does model.fit() do? What arguments must be given?\n",
        "  - model.fit() is the function that trains your model.\n",
        "  - It tells the model:\n",
        "    - \"Here is the input data (X) and the correct answers (y) ‚Äî now learn the patterns!\"\n",
        "\n",
        "\n",
        "  - Argument\n",
        "    - X_train : Input features (independent vars)\n",
        "    - y_train\t: Target values (dependent var/labels)\n",
        "    - epochs : Number of times to run through the data\n",
        "    - batch_size : Size of data chunk per weight update\n",
        "\n",
        "\n",
        "# 19. What does model.predict() do? What arguments must be given?\n",
        "  - model.predict() is used after training, to make predictions on new/unseen data.\n",
        "\n",
        "  - Argument:\n",
        "    - X_test :- The input data (features) for which you want predictions\n",
        "\n",
        "  - X_test should have the same number of features as X_train used during training.\n",
        "\n",
        "  - What Does It Return\n",
        "    - For regression models: predicted numeric values\n",
        "    - For classification models: predicted class labels or probabilities\n",
        "\n",
        "\n",
        "\n",
        "# 20. What are continuous and categorical variables?\n",
        "  - same as 5th question's answer\n",
        "\n",
        "\n",
        "\n",
        "# 21. What is feature scaling? How does it help in Machine Learning?\n",
        "  - Feature Scaling is the process of normalizing or standardizing the range of independent variables (features) so that they are on a similar scale.\n",
        "\n",
        "  - It helps make sure no feature dominates the others just because of its larger values.\n",
        "\n",
        "  - How It Helps:\n",
        "    - Speeds up training\n",
        "    - Improves model accuracy\n",
        "    - Makes gradient descent converge faster\n",
        "    - Prevents features with large scales from dominating\n",
        "\n",
        "\n",
        "\n",
        "# 22. How do we perform scaling in Python?\n",
        "  -  steps to perform scaling in python:-\n",
        "    - 1. Import the Scalers\n",
        "    - 2. Sample Dataset\n",
        "    - 3. Standard Scaling (Z-score normalization)\n",
        "    - 4. Min-Max Scaling (Normalization)\n",
        "    - 5. Robust Scaling\n",
        "    \n",
        "\n",
        "\n",
        "# 23. What is sklearn.preprocessing?\n",
        "  - sklearn.preprocessing is a module in Scikit-learn that provides tools to prepare your data before feeding it into a machine learning model.\n",
        "\n",
        "  - It includes techniques for scaling, normalizing, encoding, and transforming data.\n",
        "\n",
        "\n",
        "\n",
        "# 24. How do we split data for model fitting (training and testing) in Python?\n",
        "  - We use train_test_split() from sklearn.model_selection.\n",
        "\n",
        "  - What Each Part Means:\n",
        "    - X : Input features (independent variables)\n",
        "    - y :\tTarget values (dependent variable/labels)\n",
        "    - test_size=0.2\t: 20% data for testing, 80% for training\n",
        "    - random_state : Sets a seed so your split is reproducible\n",
        "\n",
        "\n",
        "\n",
        "# 25. Explain data encoding?\n",
        "  - Data encoding means converting categorical (non-numeric) data into numeric format so that machine learning models can understand and use it.\n",
        "\n",
        "  - ML models work with numbers, not text ‚Äî so encoding turns values like \"Red\", \"Green\", or \"Yes\" into usable numbers.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jl1VtjlUOusk"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "L7L1DC0iyUTI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}